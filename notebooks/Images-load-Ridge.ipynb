{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from lxml import etree\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps as IO\n",
    "import cv2\n",
    "\n",
    "import scipy.io\n",
    "from scipy.cluster.vq import vq, kmeans2, whiten\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "my_data = \"../data\"\n",
    "annotations = my_data + '/Annotation'        # BO file to be merged with additional information\n",
    "images = my_data + '/Images' # SAP file with order fulfilment dates\n",
    "cropped = my_data + '/Cropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Number of dogs breeds to include\n",
    "nb_breeds = 3\n",
    "\n",
    "# Number of clusters for the kMeans clustering of image descriptors\n",
    "n_clusters = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to read picture information from a matlab file\n",
    "def load_img_from_mat(mat_file):\n",
    "\n",
    "    mat_data = scipy.io.loadmat(mat_file)\n",
    "    # load annotations for each picture\n",
    "    dogs_annotation = []\n",
    "    \n",
    "    for img_annotation in mat_data['annotation_list']:\n",
    "        dog_annotation = str(img_annotation[0][0])\n",
    "        dogs_annotation.append(dog_annotation)\n",
    "\n",
    "    # load picture filenames and path for each picture contained in mat file\n",
    "    dogs_full_path = []\n",
    "    dogs_folder = []\n",
    "    dogs_file = []\n",
    "\n",
    "    for img_file in mat_data['file_list']:\n",
    "        dog_full_path = str(img_file[0][0])\n",
    "        folder, filen =  dog_full_path.split('/')\n",
    "        dogs_full_path.append(dog_full_path)\n",
    "        dogs_folder.append(folder)\n",
    "        dogs_file.append(filen)\n",
    "\n",
    "    # Create dataframe with these informations\n",
    "    file_df = pd.DataFrame({'file' : dogs_file,\n",
    "                             'folder' : dogs_folder,\n",
    "                             'full_path' : dogs_full_path,\n",
    "                             'annotation' : dogs_annotation})\n",
    "    \n",
    "    # Load label information and create a complete dataframe\n",
    "    labels_df = pd.DataFrame(mat_data['labels'], columns = ['label'])\n",
    "    file_df = file_df.join(labels_df)\n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to read a file picture\n",
    "def load_img(img_folder, img_file):\n",
    "    picture_file = join(cropped, img_folder, img_file)\n",
    "    img = Image.open(picture_file)\n",
    "    img = IO.grayscale(img)\n",
    "    img = IO.equalize(img)\n",
    "    img_sift = np.array(img)\n",
    "    return img_sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SIFT features from a dataframe of pictures\n",
    "# Passed dataframe must have 'folder' and 'file columns'\n",
    "def sift_extract(pict_df):\n",
    "    start_time = time.time()\n",
    "    lap_time = start_time\n",
    "    \n",
    "    # Variable to hold all descriptors\n",
    "    descriptors_list = []\n",
    "    \n",
    "    # Variable to hold for each picture the number of descriptors\n",
    "    descriptors_number = []\n",
    "    img_index = 0\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    for dog_folder, dog_file in np.array(pict_df[['folder', 'file']]):\n",
    "        gray_img = load_img(dog_folder, dog_file)\n",
    "\n",
    "        # Get SIFT keypoints and descriptors for each image\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "\n",
    "        # Add this image descriptors to the list\n",
    "        descriptors_number.append(len(descriptors))\n",
    "        for descriptor in descriptors:\n",
    "            descriptors_list.append(descriptor)\n",
    "        img_index += 1\n",
    "\n",
    "        if (img_index % 500) == 0:\n",
    "            print(\"{0} images processed in {1} seconds per batch of 500\".format(img_index, time.time() - lap_time))\n",
    "            lap_time = time.time()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"temps de traitement SIFT features: %15.2f secondes\" % (end_time - start_time))\n",
    "    \n",
    "    return descriptors_number, descriptors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_histograms(descriptors_number, clusters):\n",
    "    # Build matrix of histograms.\n",
    "    # Each line is a picture, each columns is a cluster ID\n",
    "    # Values are the number of times a picture belongs to a cluster, \n",
    "    # i.e. a visual word, divided by the number of pictures for this image\n",
    "    \n",
    "    desc_idx = 0\n",
    "    im_histos = np.zeros((len(descriptors_number), n_clusters), \"float64\")\n",
    "    \n",
    "    for img_idx in range(len(descriptors_number)):\n",
    "        img_desc_nb = descriptors_number[img_idx]\n",
    "        for cluster_idx in range(desc_idx, img_desc_nb + desc_idx):\n",
    "            c = clusters[cluster_idx]\n",
    "            im_histos[img_idx][c] += 1.0/img_desc_nb\n",
    "        desc_idx = img_desc_nb + desc_idx\n",
    "    return im_histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_histograms_2(descriptors_number, descriptors_list, centroids):\n",
    "    # Build matrix of histograms for test pictures\n",
    "    # Each line is a picture, each columns is a cluster ID\n",
    "    # Values are the number of times a picture belongs to a cluster, i.e. a visual word\n",
    "    \n",
    "    desc_idx = 0\n",
    "    im_histos = np.zeros((len(descriptors_number), n_clusters), \"float64\")\n",
    "    \n",
    "    for img_idx in range(len(descriptors_number)):\n",
    "        # Get array of descriptors for this image\n",
    "        img_desc_nb = descriptors_number[img_idx]\n",
    "        my_descriptors = descriptors_list[desc_idx: img_desc_nb + desc_idx]\n",
    "        \n",
    "        # Find the nearest centroid for each descriptor\n",
    "        cvect, dist = vq(my_descriptors, centroids)\n",
    "        for c in cvect:\n",
    "            im_histos[img_idx][c] += 1.0/img_desc_nb\n",
    "        desc_idx = img_desc_nb + desc_idx\n",
    "    return im_histos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures of train data: 200\n"
     ]
    }
   ],
   "source": [
    "# Load train data\n",
    "train_df = load_img_from_mat(my_data + '/train_list.mat')\n",
    "sample_train_df = train_df[train_df['label'] < nb_breeds]\n",
    "\n",
    "print 'Number of pictures of train data:', len(sample_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps de traitement SIFT features:           12.01 secondes\n",
      "Number of SIFT descriptors for train data: 129327\n",
      "Maximum number of descriptors for one picture 4191\n",
      "Minimum number of descriptors for one picture 28\n"
     ]
    }
   ],
   "source": [
    "# Extract SIFT Features from train Data and create histograms\n",
    "train_descriptors_number, train_descriptors_list = sift_extract(sample_train_df)\n",
    "\n",
    "print 'Number of SIFT descriptors for train data:', len(train_descriptors_list)\n",
    "print(\"Maximum number of descriptors for one picture {0}\".format(np.max(train_descriptors_number)))\n",
    "print(\"Minimum number of descriptors for one picture {0}\".format(np.min(train_descriptors_number)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures of test data: 137\n",
      "temps de traitement SIFT features:            9.61 secondes\n",
      "Number of SIFT descriptors for test data: 105352\n"
     ]
    }
   ],
   "source": [
    "# Load test data and get SIFT descriptors\n",
    "test_df = load_img_from_mat(my_data + '/test_list.mat')\n",
    "sample_test_df = test_df[test_df['label'] < nb_breeds]\n",
    "\n",
    "print 'Number of pictures of test data:', len(sample_test_df)\n",
    "\n",
    "test_descriptors_number, test_descriptors_list = sift_extract(sample_test_df)\n",
    "\n",
    "print 'Number of SIFT descriptors for test data:', len(test_descriptors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(n_clusters):\n",
    "    # Do a clustering of the feature descriptors\n",
    "    train_centroids, train_clusters = kmeans2(whiten(train_descriptors_list), n_clusters)\n",
    "\n",
    "    train_histos = build_histograms_2(train_descriptors_number, train_descriptors_list, train_centroids)\n",
    "\n",
    "    test_histos = build_histograms_2(test_descriptors_number, test_descriptors_list, train_centroids)\n",
    "\n",
    "    # Define X array and Y vector for the supervised classification\n",
    "    X = train_histos\n",
    "    Y = sample_train_df['label']\n",
    "\n",
    "    # Fit a Random Forest\n",
    "    rdc = RidgeClassifier()\n",
    "    rdc.fit(X, Y)\n",
    "\n",
    "    score = rdc.score(test_histos,sample_test_df['label'])\n",
    "    \n",
    "    print(\"Score for {0} clusters : {1:.2%}\".format(n_clusters, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for 3 clusters : 54.01%\n",
      "Score for 6 clusters : 57.66%\n",
      "Score for 9 clusters : 62.77%\n",
      "Score for 12 clusters : 67.15%\n",
      "Score for 15 clusters : 64.96%\n",
      "Score for 18 clusters : 67.88%\n",
      "Score for 21 clusters : 66.42%\n",
      "Score for 24 clusters : 67.15%\n",
      "Score for 27 clusters : 72.99%\n"
     ]
    }
   ],
   "source": [
    "for cluster_nb in range (nb_breeds, nb_breeds*10, nb_breeds):\n",
    "    eval_score(cluster_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_histos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-8c6916339262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_histos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_histos' is not defined"
     ]
    }
   ],
   "source": [
    "train_histos[50]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
