{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from lxml import etree\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps as IO\n",
    "import cv2\n",
    "\n",
    "import scipy.io\n",
    "from scipy.cluster.vq import vq, kmeans2, whiten\n",
    "\n",
    "# remove this ?\n",
    "# from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "my_data = \"../data\"\n",
    "annotations = my_data + '/Annotation'        # BO file to be merged with additional information\n",
    "images = my_data + '/Images' # SAP file with order fulfilment dates\n",
    "cropped = my_data + '/Cropped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_breeds = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to read picture information from a matlab file\n",
    "def load_img_from_mat(mat_file):\n",
    "\n",
    "    mat_data = scipy.io.loadmat(mat_file)\n",
    "    # load annotations for each picture\n",
    "    dogs_annotation = []\n",
    "    \n",
    "    for img_annotation in mat_data['annotation_list']:\n",
    "        dog_annotation = str(img_annotation[0][0])\n",
    "        dogs_annotation.append(dog_annotation)\n",
    "\n",
    "    # load picture filenames and path for each picture contained in mat file\n",
    "    dogs_full_path = []\n",
    "    dogs_folder = []\n",
    "    dogs_file = []\n",
    "\n",
    "    for img_file in mat_data['file_list']:\n",
    "        dog_full_path = str(img_file[0][0])\n",
    "        folder, filen =  dog_full_path.split('/')\n",
    "        dogs_full_path.append(dog_full_path)\n",
    "        dogs_folder.append(folder)\n",
    "        dogs_file.append(filen)\n",
    "\n",
    "    # Create dataframe with these informations\n",
    "    file_df = pd.DataFrame({'file' : dogs_file,\n",
    "                             'folder' : dogs_folder,\n",
    "                             'full_path' : dogs_full_path,\n",
    "                             'annotation' : dogs_annotation})\n",
    "    \n",
    "    # Load label information and create a complete dataframe\n",
    "    labels_df = pd.DataFrame(mat_data['labels'], columns = ['label'])\n",
    "    file_df = file_df.join(labels_df)\n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to read a file picture\n",
    "def load_img(img_folder, img_file):\n",
    "    picture_file = join(cropped, img_folder, img_file)\n",
    "    img = Image.open(picture_file)\n",
    "    img = IO.grayscale(img)\n",
    "    img = IO.equalize(img)\n",
    "    img_sift = np.array(img)\n",
    "    return img_sift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_extract(pict_df):\n",
    "    start_time = time.time()\n",
    "    lap_time = start_time\n",
    "    \n",
    "    descriptors_list = []\n",
    "    descriptors_number = []\n",
    "    img_index = 0\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    for dog_folder, dog_file in np.array(pict_df[['folder', 'file']]):\n",
    "        gray_img = load_img(dog_folder, dog_file)\n",
    "\n",
    "        # Get SIFT keypoints and descriptors for each image\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "\n",
    "        # Add this image descriptors to the list\n",
    "        descriptors_number.append(len(descriptors))\n",
    "        for descriptor in descriptors:\n",
    "            descriptors_list.append(descriptor)\n",
    "        img_index += 1\n",
    "\n",
    "        if (img_index % 500) == 0:\n",
    "            print(\"{0} images processed in {1} seconds per batch of 500\".format(img_index, time.time() - lap_time))\n",
    "            lap_time = time.time()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"temps de traitement SIFT features: %15.2f secondes\" % (end_time - start_time))\n",
    "    \n",
    "    return descriptors_number, descriptors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures of train data: 2900\n",
      "Number of SIFT descriptors for train data: 2304719\n"
     ]
    }
   ],
   "source": [
    "# Load train data and get SIFT descriptors\n",
    "train_df = load_img_from_mat(my_data + '/train_list.mat')\n",
    "sample_train_df = train_df[train_df['label'] < nb_breeds]\n",
    "train_descriptors_number, train_descriptors_list = sift_extract(sample_train_df)\n",
    "\n",
    "print 'Number of pictures of train data:', len(train_descriptors_number)\n",
    "\n",
    "print 'Number of SIFT descriptors for train data:', len(train_descriptors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq, kmeans2, whiten\n",
    "n_clusters = 50\n",
    "\n",
    "# Do a clustering of the feature descriptors\n",
    "centroids, clusters = kmeans2(train_descriptors_list, n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304719"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build matrix of histograms.\n",
    "# Each line is a picture, each columns is a cluster ID\n",
    "# Values are the number of times a picture belongs to a cluster, i.e. a visual word\n",
    "desc_idx = 0\n",
    "im_histos = np.zeros((len(train_descriptors_number), n_clusters), \"float64\")\n",
    "for img_idx in range(len(train_descriptors_number)):\n",
    "    img_desc_nb = train_descriptors_number[img_idx]\n",
    "    for cluster_idx in range(desc_idx, img_desc_nb + desc_idx):\n",
    "        c = clusters[cluster_idx]\n",
    "        im_histos[img_idx][c] += 1.0/img_desc_nb\n",
    "    desc_idx = img_desc_nb + desc_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_desc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_descriptors_number[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(im_histos[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01317957, 0.0214168 , 0.01317957, 0.01482702, 0.0247117 ,\n",
       "       0.01812191, 0.02635914, 0.0247117 , 0.01976936, 0.01812191,\n",
       "       0.0247117 , 0.00494234, 0.01976936, 0.02306425, 0.00823723,\n",
       "       0.01976936, 0.0247117 , 0.0214168 , 0.0247117 , 0.01647446,\n",
       "       0.01976936, 0.02306425, 0.01812191, 0.02965404, 0.0247117 ,\n",
       "       0.01317957, 0.00494234, 0.01647446, 0.0247117 , 0.02635914,\n",
       "       0.02965404, 0.0247117 , 0.02306425, 0.01153213, 0.02800659,\n",
       "       0.01482702, 0.00988468, 0.02635914, 0.02635914, 0.01482702,\n",
       "       0.0214168 , 0.02635914, 0.00988468, 0.01482702, 0.03130148,\n",
       "       0.01812191, 0.01647446, 0.03294893, 0.00658979, 0.02965404])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_histos[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting duration 4.95799994469 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "# Do a multi label classification\n",
    "X = im_histos\n",
    "Y = sample_train_df['label']\n",
    "\n",
    "MultiLabelClassif = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "start =  time.time()\n",
    "MultiLabelClassif.fit(X, Y)\n",
    "end =  time.time()\n",
    "print(\"Fitting duration {0} seconds\".format(end - start) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2900L,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pictures of test data: 2384\n",
      "Number of SIFT descriptors for test data: 1927652\n"
     ]
    }
   ],
   "source": [
    "# Load test data and get SIFT descriptors\n",
    "test_df = load_img_from_mat(my_data + '/test_list.mat')\n",
    "sample_test_df = test_df[test_df['label'] < nb_breeds]\n",
    "test_descriptors_number, test_descriptors_list = sift_extract(sample_test_df)\n",
    "\n",
    "print 'Number of pictures of test data:', len(test_descriptors_number)\n",
    "\n",
    "print 'Number of SIFT descriptors for test data:', len(test_descriptors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build matrix of histograms for test pictures\n",
    "# Each line is a picture, each columns is a cluster ID\n",
    "# Values are the number of times a picture belongs to a cluster, i.e. a visual word\n",
    "desc_idx_test = 0\n",
    "im_histos_test = np.zeros((len(test_descriptors_number), n_clusters), \"float64\")\n",
    "for img_idx in range(len(test_descriptors_number)):\n",
    "    img_desc_nb = test_descriptors_number[img_idx]\n",
    "    my_descriptors = test_descriptors_list[desc_idx_test: img_desc_nb + desc_idx_test]\n",
    "    cvect, dist = vq(my_descriptors, centroids)\n",
    "    for c in cvect:\n",
    "        im_histos_test[img_idx][c] += 1.0/img_desc_nb\n",
    "    desc_idx_test = img_desc_nb + desc_idx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00880282, 0.01584507, 0.02464789, 0.01056338, 0.01408451,\n",
       "       0.01584507, 0.02992958, 0.02288732, 0.02816901, 0.0193662 ,\n",
       "       0.02112676, 0.01760563, 0.01760563, 0.00352113, 0.03697183,\n",
       "       0.00704225, 0.01408451, 0.02992958, 0.00880282, 0.01760563,\n",
       "       0.03169014, 0.02464789, 0.00528169, 0.01584507, 0.01760563,\n",
       "       0.01056338, 0.01056338, 0.00880282, 0.00704225, 0.0334507 ,\n",
       "       0.01408451, 0.01232394, 0.01056338, 0.05105634, 0.01056338,\n",
       "       0.02112676, 0.0193662 , 0.0193662 , 0.02992958, 0.01408451,\n",
       "       0.01408451, 0.0334507 , 0.03169014, 0.01584507, 0.01408451,\n",
       "       0.03873239, 0.02816901, 0.02464789, 0.04753521, 0.0193662 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_histos_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2384L, 50L)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(im_histos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "folder    n02085782-Japanese_spaniel\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs_labels = train_df[['folder', 'label']].drop_duplicates().set_index('label')\n",
    "#dogs_labels[dogs_labels['label']==2]\n",
    "dogs_labels.loc[2, ['folder']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predic proba for each tag to be relevant for the question\n",
    "test_predict_proba = MultiLabelClassif.predict_proba(im_histos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(folder    n02089078-black-and-tan_coonhound\n",
      "Name: 15, dtype: object, 0.04924153831950025)\n",
      "(folder    n02085620-Chihuahua\n",
      "Name: 1, dtype: object, 0.04632587539960555)\n",
      "(folder    n02086240-Shih-Tzu\n",
      "Name: 5, dtype: object, 0.04482853558014607)\n",
      "(folder    n02088238-basset\n",
      "Name: 11, dtype: object, 0.04439512584814764)\n",
      "(folder    n02092339-Weimaraner\n",
      "Name: 28, dtype: object, 0.044018910218815724)\n",
      "(folder    n02089867-Walker_hound\n",
      "Name: 16, dtype: object, 0.04395922975797525)\n",
      "(folder    n02091831-Saluki\n",
      "Name: 26, dtype: object, 0.041961646893488455)\n",
      "(folder    n02091134-whippet\n",
      "Name: 22, dtype: object, 0.04015838097472137)\n",
      "(folder    n02086910-papillon\n",
      "Name: 7, dtype: object, 0.03866206386887495)\n",
      "(folder    n02088632-bluetick\n",
      "Name: 14, dtype: object, 0.0384037253244496)\n"
     ]
    }
   ],
   "source": [
    "proposed_type = ''\n",
    "for i in test_predict_proba[10].argsort()[:-10-1:-1]:\n",
    "    proposed_type = dogs_labels.loc[i, ['folder']]\n",
    "    print(proposed_type, test_predict_proba[10][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annotation        n02085620-Chihuahua/n02085620_1765\n",
       "file                              n02085620_1765.jpg\n",
       "folder                           n02085620-Chihuahua\n",
       "full_path     n02085620-Chihuahua/n02085620_1765.jpg\n",
       "label                                              1\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_df.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2384L, 29L)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_predict_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03044937, 0.0585624 , 0.00302788, 0.03588743, 0.03117359,\n",
       "       0.04368595, 0.02395971, 0.03875954, 0.03487004, 0.03716219,\n",
       "       0.03209668, 0.03944756, 0.03255982, 0.03286392, 0.03988588,\n",
       "       0.04358016, 0.03812752, 0.02908883, 0.0330573 , 0.02962716,\n",
       "       0.03633774, 0.03707579, 0.03495838, 0.02407168, 0.03575281,\n",
       "       0.03572604, 0.03424537, 0.04396085, 0.0299984 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03839787, 0.04632588, 0.00945957, 0.0285218 , 0.03416962,\n",
       "       0.04482854, 0.02137135, 0.03866206, 0.0372451 , 0.03233565,\n",
       "       0.03521128, 0.04439513, 0.03138595, 0.03679752, 0.03840373,\n",
       "       0.04924154, 0.04395923, 0.02848204, 0.03530734, 0.01903651,\n",
       "       0.03684424, 0.02950556, 0.04015838, 0.02176741, 0.03432336,\n",
       "       0.0301878 , 0.04196165, 0.02769501, 0.04401891])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict_proba[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predict = rfc.predict(im_histos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2384"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rfc_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2384"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(im_histos_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09437919463087248"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(im_histos_test,sample_test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
