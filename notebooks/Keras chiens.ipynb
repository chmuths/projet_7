{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(123)  # for reproducibility\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read picture information from a matlab file\n",
    "def load_img_from_mat(mat_file):\n",
    "\n",
    "    mat_data = scipy.io.loadmat(mat_file)\n",
    "    # load annotations for each picture\n",
    "    dogs_annotation = []\n",
    "    \n",
    "    for img_annotation in mat_data['annotation_list']:\n",
    "        dog_annotation = str(img_annotation[0][0])\n",
    "        dogs_annotation.append(dog_annotation)\n",
    "\n",
    "    # load picture filenames and path for each picture contained in mat file\n",
    "    dogs_full_path = []\n",
    "    dogs_folder = []\n",
    "    dogs_file = []\n",
    "\n",
    "    for img_file in mat_data['file_list']:\n",
    "        dog_full_path = str(img_file[0][0])\n",
    "        folder, filen =  dog_full_path.split('/')\n",
    "        dogs_full_path.append(dog_full_path)\n",
    "        dogs_folder.append(folder)\n",
    "        dogs_file.append(filen)\n",
    "\n",
    "    # Create dataframe with these informations\n",
    "    file_df = pd.DataFrame({'file' : dogs_file,\n",
    "                             'folder' : dogs_folder,\n",
    "                             'full_path' : dogs_full_path,\n",
    "                             'annotation' : dogs_annotation})\n",
    "    \n",
    "    # Load label information and create a complete dataframe\n",
    "    labels_df = pd.DataFrame(mat_data['labels'], columns = ['label'])\n",
    "    file_df = file_df.join(labels_df)\n",
    "    \n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to read a file picture and return it as VGG-16 requires\n",
    "def load_img_file(variant, img_folder, img_file):\n",
    "    picture_file = join(variant, img_folder, img_file)\n",
    "\n",
    "    img = load_img(picture_file, target_size=(224, 224))  # Charger l'image\n",
    "    img = img_to_array(img)  # Convertir en tableau numpy\n",
    "    #img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "    img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create picture array\n",
    "def get_pict_array(pict_df):\n",
    "    # Variable to hold all pictures\n",
    "    X_pict_array = []\n",
    "    first = True\n",
    "    for dog_folder, dog_file in np.array(pict_df[['folder', 'file']]):\n",
    "        img = load_img_file(bw, dog_folder, dog_file)\n",
    "        if first:\n",
    "            X_pict_array = [img]\n",
    "            first = False\n",
    "        else:\n",
    "            X_pict_array += [img]\n",
    "            \n",
    "    return np.array(X_pict_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "my_data = \"../data\"\n",
    "images = my_data + '/Images' # Images folder\n",
    "bw = my_data + '/BWEqu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Number of dogs breeds to include\n",
    "nb_breeds = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train_df = load_img_from_mat(my_data + '/train_list.mat')\n",
    "sample_train_df = train_df[train_df['label'] <= nb_breeds]\n",
    "\n",
    "X_train = get_pict_array(sample_train_df)\n",
    "Y_train = sample_train_df['label'] - 1\n",
    "\n",
    "# Load test data\n",
    "test_df = load_img_from_mat(my_data + '/test_list.mat')\n",
    "sample_test_df = test_df[test_df['label'] <= nb_breeds]\n",
    "\n",
    "X_test = get_pict_array(sample_test_df)\n",
    "Y_test = sample_test_df['label'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3, 224, 224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Preprocess input data\n",
    "#X_train = X_train.reshape(X_train.shape[0], 1, 224, 224)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Preprocess class labels\n",
    "Y_train = np_utils.to_categorical(Y_train, nb_breeds)\n",
    "Y_test = np_utils.to_categorical(Y_test, nb_breeds)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    " \n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(3,224,224)))\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_breeds, activation='softmax'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 23s 114ms/step - loss: 3.6850 - acc: 0.5200\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 0.7295 - acc: 0.5450\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.5599 - acc: 0.7850\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.3957 - acc: 0.8250\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.2864 - acc: 0.8800\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 0.1346 - acc: 0.9700\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.1579 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 22s 110ms/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 22s 111ms/step - loss: 0.0461 - acc: 0.9950\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 22s 112ms/step - loss: 0.0229 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e914638898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Fit model on training data\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=32, epochs=10, verbose=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5930086639675781, 0.7591240888964521]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
